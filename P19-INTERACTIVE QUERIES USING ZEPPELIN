.bashrc 
export JAVA_HOME=/home/grg/jdk1.8.0_45 
export HADOOP_HOME=/home/grg/hadoop-2.9.0 
export SPARK_HOME=/home/grg/spark-2.1.1-bin-hadoop2.7 
export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin:$PATH 
#export JAVA_HOME=/usr/lip/jpm/java-8-openjdk_amd64 
export PIG_HOME=/home/grg/pig-0.12.0 
export HADOOP_HOME=/home/grg/hadoop-2.9.1 
export HIVE_HOME=/home/grg/hive-0.12.0 
export PATH=$HIVE_HOME/bin:$PATH

search firefox :http://localhost:8080/ 
cd $home
cd zeppelin-0.8.2-bin-all
bin/zeppelin-daemon.sh start
sudo bin/zeppelin-daemon.sh restart
(Zeppelin password:GRG@123

It can need datagen_10.txt 
 
val schemaString = "id name dName gender amount" 
import org.apache.spark.sql.Row 
import org.apache.spark.sql.types.{StructType, StructField, StringType}; 
val patient1 = sc.textFile("file:///home/grg/datagen_10.txt") 
val schema= StructType(schemaString.split(" ").map(fieldName => StructField(fieldName, 
StringType, true))) 
val rowRDD= patient1.map(_.split(",")).map(p=> Row(p(0), p(1),p(2),p(3),p(4))) 
val patientDf = spark.createDataFrame(rowRDD, schema) 
patientDf.registerTempTable("patient1") 
 
 
To view the Output 
%sql 
select dname, sum(amount) from patient1 group by dName
